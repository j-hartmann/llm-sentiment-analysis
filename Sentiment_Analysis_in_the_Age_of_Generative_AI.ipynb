{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j-hartmann/llm-sentiment-analysis/blob/main/Sentiment_Analysis_in_the_Age_of_Generative_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Introduction\n",
        "\n"
      ],
      "metadata": {
        "id": "SfmzzcA694WB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Google Colab provides ready-to-use Python Code to perform sentiment analysis using Large Language Models (LLMs). We use the OpenAI API for GPT-4 as exemplary use case, but you can choose any other model from OpenAI or slightly adapt the code to use other APIs (e.g., Replicate for Llama 2). We provide exemplary code to perform:\n",
        "\n",
        "*   Binary zero-shot sentiment analysis\n",
        "*   Three-class zero-shot sentiment analysis\n",
        "*   Few-shot sentiment analysis\n",
        "\n",
        "The results are stored in an Excel file. Based on the models you use it might be useful to slightly adjust the prompt for optimal results.\n",
        "\n"
      ],
      "metadata": {
        "id": "XiuxCGmX-ox7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Prepartion"
      ],
      "metadata": {
        "id": "RNgMpYruByai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Colab is designed to use an Excel file with two columns as input: A 'Review_ID' column as identificator and the 'Review' column containing all reviews for sentiment analysis. Please structure and name your input file accordingly."
      ],
      "metadata": {
        "id": "p9AQsiRWB0iu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Binary zero-shot sentiment analysis"
      ],
      "metadata": {
        "id": "wfA2ZJcL_Y80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries and import modules for API access and data handling\n",
        "# You can change the version of OpenAI based on the models you want to use\n",
        "!pip install openai==0.27.8 pandas xlrd\n",
        "import os\n",
        "import openai\n",
        "import pandas as pd\n",
        "import time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5W2FUvTO_fsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your OpenAI API key\n",
        "openai.api_key = \"Your_API_Key\"\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel('Your_Excel_File')\n",
        "\n",
        "# Convert 'Review_ID' to string\n",
        "df['Review_ID'] = df['Review_ID'].astype(str)\n",
        "\n",
        "# Extract ID and Review text\n",
        "review_ids = df['Review_ID'].tolist()\n",
        "total_reviews = df['Review'].tolist()\n",
        "\n",
        "# Optional: Split the data into batches as some APIs implement rate limits for API calls\n",
        "batch_size = 10  # Define your batch size\n",
        "review_batches = [total_reviews[i:i + batch_size] for i in range(0, len(total_reviews), batch_size)]\n",
        "review_id_batches = [review_ids[i:i + batch_size] for i in range(0, len(review_ids), batch_size)]\n",
        "\n",
        "sentiment_results = []\n",
        "\n",
        "for review_id_batch, review_batch in zip(review_id_batches, review_batches):\n",
        "    # Prepare the prompt\n",
        "    reviews = '\\n'.join(f'{review_id}: \"{review}\"' for review_id, review in zip(review_id_batch, review_batch))\n",
        "    prompt = f\"Classify the sentiment in these reviews as positive or negative:\\n{reviews}\"\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Call the OpenAI API\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\",\n",
        "                temperature=0, #set the temperature parameter to 0 to make output near deterministic\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": prompt},\n",
        "                    {\"role\": \"user\", \"content\": \"\"}\n",
        "                ]\n",
        "            )\n",
        "            break  # if API call is successful, break the loop. If rate limit is exceeded, include waiting time\n",
        "        except Exception as e:\n",
        "            if \"Rate limit exceeded\" in str(e):\n",
        "                print(\"Rate limit exceeded. Waiting for 60 seconds.\")\n",
        "                time.sleep(60)\n",
        "            else:\n",
        "                print(f\"Unexpected error: {str(e)}. Waiting for 5 seconds before retrying.\")\n",
        "                time.sleep(5)\n",
        "\n",
        "    # Process response text\n",
        "    response_text = response['choices'][0]['message']['content']\n",
        "    response_lines = response_text.split(\"\\n\")\n",
        "\n",
        "    for line in response_lines:\n",
        "        try:\n",
        "            review_id, sentiment = line.split(\":\")\n",
        "            sentiment_results.append((review_id, sentiment.lower().strip()))\n",
        "        except ValueError:\n",
        "            print(f\"Unexpected format: {line}\")\n",
        "\n",
        "# Create a DataFrame from the sentiment results\n",
        "df_results = pd.DataFrame(sentiment_results, columns=[\"Review_ID\", \"Sentiment\"])\n",
        "\n",
        "# Save DataFrame to Excel\n",
        "df_results.to_excel('Your_File_Name.xlsx', index=False)"
      ],
      "metadata": {
        "id": "pGvS4dUxl7Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Three-class zero-shot sentiment analysis"
      ],
      "metadata": {
        "id": "owb8judLqQlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can use the same code as in the binary classification tasks, and just replace the prompt\n",
        "#prompt = f\"Classify the sentiment in these tweets as positive, negative, or neutral:\\n{reviews}\""
      ],
      "metadata": {
        "id": "DTUYpEDhqVSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-shot sentiment analysis"
      ],
      "metadata": {
        "id": "LxdyukCLq26X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can use the same code as in the binary classification task, and just replace the prompt. Make sure to include the few-shot examples incl. the ground truth from your dataset.\n",
        "# prompt = f\"Classify the sentiment of the following tweets as positive, negative, or neutral:\\n{reviews}\"\n",
        "   # \"Here are a few examples with the sentiment in brackets:\"\n",
        "   # \"Example 1: ... ('ground truth')\\n\"\n",
        "   # \"Example 2: ... ('ground truth')\\n\"\n",
        "   # \"Example 3: ... ('ground truth')\\n\"\n",
        "   # \"Example 4: ... ('ground truth')\\n\"\n",
        "   # \"Example 5: ... ('ground truth')\\n\"\n",
        "   # \"Example 6: ... ('ground truth')\\n\"\n"
      ],
      "metadata": {
        "id": "b9n0oRkJq7fN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}